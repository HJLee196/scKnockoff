% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/create_multi_decomp_knock.R
\name{create_multi_decomp_knock}
\alias{create_multi_decomp_knock}
\title{Multiple knockoff construction using matrix decomposition}
\usage{
create_multi_decomp_knock(np_data.matrix.imp, Xl, Bl, err, PC, m)
}
\arguments{
\item{np_data.matrix.imp}{A numeric matrix of dimension n x p containing the
imputed data.}

\item{Xl}{A numeric matrix of dimension n x k containing latent factors, where
k = PC plus the number of additional covariates.}

\item{Bl}{A numeric matrix of dimension k x p containing factor loadings.}

\item{err}{A numeric vector of length p containing estimated error variances.}

\item{PC}{A positive integer specifying the number of latent factors,
excluding additional covariates.}

\item{m}{A positive integer specifying the number of knockoffs to be constructed.}
}
\value{
A list of length \code{m}. Each element is a numeric matrix of dimension
\eqn{n \times p} containing one knockoff copy constructed using the
matrix decomposition-based covariance estimate and the multiple
knockoff procedure. The returned matrices are not rescaled; rescaling
should be performed separately (e.g., using
\code{rescale_knockoff}).
}
\description{
Multiple knockoff construction using matrix decomposition
}
\details{
Constructs multiple knockoff copies using a matrix decomposition-based
covariance estimator and a multiple knockoff procedure. The \code{m}
knockoff copies are generated jointly so that the required
exchangeability property holds simultaneously across the original
variables and all knockoff copies. Compared to full covariance-based
knockoff construction, this approach reduces computational and memory
costs in high-dimensional settings.
}
\examples{
set.seed(2024)
# Create dataset
Xl <- matrix(rnorm(1000),nrow = 100)
Bl <- matrix(rnorm(800),ncol=80)
err <- abs(rnorm(80,sd=3))

E <- matrix(NA,nrow = 100,ncol = 80)
for(i in 1:80){
  E[,i] <- rnorm(100, sd = err[i])
}

np_data <- Xl\%*\%Bl + E

rownames(np_data) <- paste0("r", 1:100)
colnames(np_data) <- paste0("c", 1:80)

# Create missing data
miss <- sample(1:prod(dim(np_data)),floor(prod(dim(np_data))*0.6))
np_data[miss] <- 0

np_data_exp <- matrix(1,nrow=100,ncol=80)
np_data_exp[miss] <- 0

np_data_exp.count <- apply(np_data_exp,2,sum)

# Center target matrix, but only center the expressed parts.
np_data.avg <- (colSums(np_data, na.rm = TRUE))/(np_data_exp.count-1)
np_data_centered <- sweep(np_data,2,np_data.avg,FUN = "-")*(np_data_exp)

# Impute missing values
np_data_imp <- sc_softImpute(np_data_centered,np_data_exp,Xl[,1:3],PC=min(np_data_exp.count)-5)

# multidecomp knockoff construction
m <- 5
multi_decomp_knock <- create_multi_decomp_knock(np_data_imp$X_imp,
                                                np_data_imp$Xl,
                                                np_data_imp$Bl,
                                                np_data_imp$err,
                                                np_data_imp$PC,
                                                m)

# Rescale each of the knockoff copies
multi_decomp_knock <- rescale_knockoff(multi_decomp_knock, np_data_exp, np_data.avg)

}
\references{
Roquero Gimenez, J., and Zou, J. (2019).
\emph{Improving the Stability of the Knockoff Procedure: Multiple Simultaneous
Knockoffs and Entropy Maximization}.
In \emph{Proceedings of the 22nd International Conference on Artificial Intelligence
and Statistics}, pp. 2184--2192.

He, Z., Chu, B., Yang, J., Gu, J., Chen, Z., Liu, L., Morrison, T.,
Belloy, M. E., Qi, X., Hejazi, N., Mathur, M., Le Guen, Y., Tang, H.,
Hastie, T., Ionita-Laza, I., Sabatti, C., and Candes, E. (2024).
\emph{Beyond Guilty by Association at Scale: Searching for Causal Variants
on the Basis of Genome-Wide Summary Statistics}.
bioRxiv preprint.
\doi{10.1101/2024.02.28.582621}
}
\seealso{
Other create: 
\code{\link{create_decomp_knock}()},
\code{\link{create_lr_knock}()},
\code{\link{create_multi_lr_knock}()}
}
\concept{create}
